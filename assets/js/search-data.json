{
  
    
        "post0": {
            "title": "Managing answerALS metadata in a SQLite database in R",
            "content": "# installation install.packages(&quot;RSQLite&quot;) . library(dplyr) library(dbplyr) library(ggplot2) library(glue) library(readr) library(RSQLite) . The answerALS dataset . The answerALS project has collected clincal data from ~ 1000 subjects with and without Amyotrophic lateral sclerosis (ALS). . A broad consortium of Scientists has collected biological samples, e.g. motor neurons grown in tissue culture, and is now collecting genomic, transcriptomic, proteomic and epigenetic data. . Metadata . With each data release, the answerALS consortium is also publishing a set of metadata, e.g. CSV files with information about each study participant. . For example, data from answerALS release v4.0 is available for download here . For this post, I have downloaded the available metadata as a .zip archive and uncompressed it in metadata directory. . dir(&quot;metadata&quot;) . &lt;ol class=list-inline&gt;&#39;aals_dataportal_datatable.csv&#39; | &#39;aals_participants.csv&#39; | &#39;aals_released_files.csv&#39; | &#39;clinical&#39; | &#39;Clinical_Dictionary.csv&#39; | &lt;/ol&gt; There are 3 high level summary tables: . aals_dataportal_datatable.csv | aals_participants.csv | aals_released_files.csv | as well as the clinical dictionary with descriptions of each field and the contained values. . In addition, the clinical folder contains an additional 33 CSV files. . Each file contains the Participant_ID column, with a unique key for each participant, which can be used to join information across the tables. . Note: The answerALS project has conducted a longitudinal study, e.g. participants were assessed at multiple visits. . For example, the ALSFRS_R.csv file contains the Visit_Name that specifies the visit at which the measurements were obtained. The Visit_Date column indicates the time (in days) that passed between the Screening visit (day 0) and the following visits. . This information needs to be included in join operations to ensure that longitudinal measurements are associated with the correct time points. . frs &lt;- read.csv(file.path(&quot;metadata&quot;, &quot;clinical&quot;, &quot;ALSFRS_R.csv&quot;)) frs %&gt;% dplyr::count(Visit_Name) %&gt;% dplyr::top_n(n = 5) . Selecting by n . A data.frame: 5 √ó 2 Visit_Namen . &lt;chr&gt;&lt;int&gt; . ANSWER-ALS Screening Visit | 929 | . ANSWER-ALS Visit 2 | 695 | . ANSWER-ALS Visit 3 | 549 | . ANSWER-ALS Visit 4 | 414 | . ANSWER-ALS Visit 5 | 325 | . Creating a metadata database . The metadata is shared in the form of comma-separated values (CSV), e.g. plain text files. For analyses that use multiple tables, it is convenient to create a SQLite database, which can then be queried using SQL or dplyr. . The RSQLite R package enables us to create, query and modify a SQLite database from R. . Creating a new database . First, we create a new, empty SQLite database in the current working directory simply by connecting to it. . conn &lt;- dbConnect(RSQLite::SQLite(), &quot;answerALS.db&quot;) . dir(pattern = &quot;.db$&quot;) . &#39;answerALS.db&#39; dbListTables(conn) . Next, we read each of the answerALS CSV files and add there content as separate tables to the database. . for (path in dir(&quot;metadata&quot;, pattern = &quot;.csv$&quot;, full.names = TRUE, recursive = TRUE)) { df &lt;- readr::read_csv(path, col_types = readr::cols(), guess_max = 1e5) table_name &lt;- tools::file_path_sans_ext(basename(path)) dbWriteTable(conn, table_name, df) } . dbListTables(conn) . &lt;ol class=list-inline&gt;&#39;AALSDXFX&#39; | &#39;AALSHXFX&#39; | &#39;ALSFRS_R&#39; | &#39;ALS_CBS&#39; | &#39;ALS_Gene_Mutations&#39; | &#39;ANSASFD&#39; | &#39;ANSWER_ALS_Medications_Log&#39; | &#39;ANSWER_ALS_MobileApp&#39; | &#39;Ashworth_Spasticity_Scale&#39; | &#39;Auxiliary_Chemistry&#39; | &#39;Auxiliary_Chemistry_Labs&#39; | &#39;CNS_Lability_Scale&#39; | &#39;Cerebrospinal_Fluid&#39; | &#39;Clinical_Dictionary&#39; | &#39;DNA_Sample_Collection&#39; | &#39;Demographics&#39; | &#39;Diaphragm_Pacing_System_Device&#39; | &#39;Family_History_Log&#39; | &#39;Feeding_Tube_Placement&#39; | &#39;Grip_Strength_Testing&#39; | &#39;Hand_Held_Dynamometry&#39; | &#39;Medical_History&#39; | &#39;Mortality&#39; | &#39;NEUROLOG&#39; | &#39;NIV_Log&#39; | &#39;PBMC_Sample_Collection&#39; | &#39;Permanent_Assisted_Ventilation&#39; | &#39;Plasma_Sample&#39; | &#39;Reflexes&#39; | &#39;Serum_Sample&#39; | &#39;Tracheostomy&#39; | &#39;Vital_Capacity&#39; | &#39;Vital_Signs&#39; | &#39;aals_dataportal_datatable&#39; | &#39;aals_participants&#39; | &#39;aals_released_files&#39; | &#39;subjects&#39; | &lt;/ol&gt; Now that the have all of the metadata information in a single SQLite database, we can analyze individual tables, join information across tables, or create views to make future queries simpler. . Querying the database . If you like to use a graphical user interface, you can explore the data e.g. using the DB Browser for SQLite (DB4S) GUI. . . In our R session, we can use either dplyr syntax: . participants &lt;- tbl(conn, &quot;aals_participants&quot;) participants . # Source: table&lt;aals_participants&gt; [?? x 8] # Database: sqlite 3.34.1 [answerALS.db] Participant_ID GUID Case_Control Sex Cohort Diagnosis `Enrollment Sta‚Ä¶ &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 CASE-NEUAA295‚Ä¶ NEUA‚Ä¶ Case Male ALS NA Other (specify)‚Ä¶ 2 CASE-NEUAA599‚Ä¶ NEUA‚Ä¶ Case Fema‚Ä¶ ALS NA Subject died (C‚Ä¶ 3 CASE-NEUAB000‚Ä¶ NEUA‚Ä¶ Case Fema‚Ä¶ ALS NA Subject died (C‚Ä¶ 4 CASE-NEUAC617‚Ä¶ NEUA‚Ä¶ Case Male Non-A‚Ä¶ Primary ‚Ä¶ Other (specify)‚Ä¶ 5 CASE-NEUAD142‚Ä¶ NEUA‚Ä¶ Case Male ALS NA Subject died (C‚Ä¶ 6 CASE-NEUAD542‚Ä¶ NEUA‚Ä¶ Case Male ALS NA Other (specify)‚Ä¶ 7 CASE-NEUAD952‚Ä¶ NEUA‚Ä¶ Case Fema‚Ä¶ ALS NA Subject died (C‚Ä¶ 8 CASE-NEUAE228‚Ä¶ NEUA‚Ä¶ Case Male ALS NA Other (specify)‚Ä¶ 9 CASE-NEUAE431‚Ä¶ NEUA‚Ä¶ Case Male Non-A‚Ä¶ Primary ‚Ä¶ Other (specify)‚Ä¶ 10 CASE-NEUAE806‚Ä¶ NEUA‚Ä¶ Case Fema‚Ä¶ Non-A‚Ä¶ Primary ‚Ä¶ Other (specify)‚Ä¶ # ‚Ä¶ with more rows, and 1 more variable: Notes &lt;chr&gt; . participants %&gt;% dplyr::count(Sex) . # Source: lazy query [?? x 2] # Database: sqlite 3.34.1 [answerALS.db] Sex n &lt;chr&gt; &lt;int&gt; 1 NA 9 2 Female 418 3 Male 614 . participants %&gt;% dplyr::group_by(Sex, Cohort) %&gt;% dplyr::count() . # Source: lazy query [?? x 3] # Database: sqlite 3.34.1 [answerALS.db] # Groups: Sex Sex Cohort n &lt;chr&gt; &lt;chr&gt; &lt;int&gt; 1 NA ALS 6 2 NA Healthy Control 3 3 Female ALS 317 4 Female Asymptomatic ALS Gene carrier 7 5 Female Healthy Control 70 6 Female Non-ALS MND 24 7 Male ALS 532 8 Male Asymptomatic ALS Gene carrier 5 9 Male Healthy Control 35 10 Male Non-ALS MND 42 . frs &lt;- tbl(conn, &quot;ALSFRS_R&quot;) frs . # Source: table&lt;ALSFRS_R&gt; [?? x 28] # Database: sqlite 3.34.1 [answerALS.db] Participant_ID SubjectUID Form_Name Visit_Name Visit_Date alsfdn alsfdnsp &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 1 CASE-NEUAA295‚Ä¶ NEUAA295H‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 588 1 NA 2 CASE-NEUAA295‚Ä¶ NEUAA295H‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 210 1 NA 3 CASE-NEUAA295‚Ä¶ NEUAA295H‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 434 1 NA 4 CASE-NEUAA295‚Ä¶ NEUAA295H‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 119 1 NA 5 CASE-NEUAA295‚Ä¶ NEUAA295H‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 0 1 NA 6 CASE-NEUAA599‚Ä¶ NEUAA599T‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 154 1 NA 7 CASE-NEUAA599‚Ä¶ NEUAA599T‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 0 1 NA 8 CASE-NEUAB000‚Ä¶ NEUAB000N‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 114 1 NA 9 CASE-NEUAB000‚Ä¶ NEUAB000N‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 0 1 NA 10 CASE-NEUAB000‚Ä¶ NEUAB000N‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 157 1 NA # ‚Ä¶ with more rows, and 21 more variables: alsfrs1 &lt;dbl&gt;, alsfrs2 &lt;dbl&gt;, # alsfrs3 &lt;dbl&gt;, alsfrs4 &lt;dbl&gt;, alsfrs5 &lt;dbl&gt;, alsfrs5a &lt;dbl&gt;, # alsfrs5b &lt;dbl&gt;, alsfrs6 &lt;dbl&gt;, alsfrs7 &lt;dbl&gt;, alsfrs8 &lt;dbl&gt;, alsfrs9 &lt;dbl&gt;, # alsfrsdt &lt;dbl&gt;, alsfrsmd &lt;dbl&gt;, alsfrsr1 &lt;dbl&gt;, alsfrsr2 &lt;dbl&gt;, # alsfrsr3 &lt;dbl&gt;, alsfrsrp &lt;dbl&gt;, alsfrssp &lt;chr&gt;, alsfrst &lt;dbl&gt;, # source &lt;dbl&gt;, sourcesp &lt;chr&gt; . frs %&gt;% dplyr::filter(Visit_Name == &quot;ANSWER-ALS Screening Visit&quot;) %&gt;% head(5) . # Source: lazy query [?? x 28] # Database: sqlite 3.34.1 [answerALS.db] Participant_ID SubjectUID Form_Name Visit_Name Visit_Date alsfdn alsfdnsp &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 1 CASE-NEUAA295‚Ä¶ NEUAA295H‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 0 1 NA 2 CASE-NEUAA599‚Ä¶ NEUAA599T‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 0 1 NA 3 CASE-NEUAB000‚Ä¶ NEUAB000N‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 0 1 NA 4 CASE-NEUAC617‚Ä¶ NEUAC617G‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 0 1 NA 5 CASE-NEUAD142‚Ä¶ NEUAD142R‚Ä¶ ALSFRS-R ANSWER-AL‚Ä¶ 0 1 NA # ‚Ä¶ with 21 more variables: alsfrs1 &lt;dbl&gt;, alsfrs2 &lt;dbl&gt;, alsfrs3 &lt;dbl&gt;, # alsfrs4 &lt;dbl&gt;, alsfrs5 &lt;dbl&gt;, alsfrs5a &lt;dbl&gt;, alsfrs5b &lt;dbl&gt;, # alsfrs6 &lt;dbl&gt;, alsfrs7 &lt;dbl&gt;, alsfrs8 &lt;dbl&gt;, alsfrs9 &lt;dbl&gt;, alsfrsdt &lt;dbl&gt;, # alsfrsmd &lt;dbl&gt;, alsfrsr1 &lt;dbl&gt;, alsfrsr2 &lt;dbl&gt;, alsfrsr3 &lt;dbl&gt;, # alsfrsrp &lt;dbl&gt;, alsfrssp &lt;chr&gt;, alsfrst &lt;dbl&gt;, source &lt;dbl&gt;, sourcesp &lt;chr&gt; . participants %&gt;% dplyr::filter(Sex == &quot;Male&quot;, Cohort == &quot;ALS&quot;) %&gt;% head(5) %&gt;% dplyr::inner_join(frs) %&gt;% dplyr::select(Participant_ID, Cohort, Visit_Name, Visit_Date, alsfrst) %&gt;% dplyr::arrange(Participant_ID, Visit_Date) %&gt;% dplyr::collect() %&gt;% ggplot(aes(x = Visit_Date, y = alsfrst, color = Participant_ID)) + geom_point() + geom_line() . Joining, by = &#34;Participant_ID&#34; . or the equivalent SQL statements: . dbGetQuery(conn, glue_sql(&quot;SELECT * FROM `ALSFRS_R` WHERE (`Visit_Name` = &#39;ANSWER-ALS Screening Visit&#39;) LIMIT 5&quot;)) . A data.frame: 5 √ó 28 Participant_IDSubjectUIDForm_NameVisit_NameVisit_Datealsfdnalsfdnspalsfrs1alsfrs2alsfrs3‚ãØalsfrsdtalsfrsmdalsfrsr1alsfrsr2alsfrsr3alsfrsrpalsfrsspalsfrstsourcesourcesp . &lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;‚ãØ&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt; . CASE-NEUAA295HHE | NEUAA295HHE | ALSFRS-R | ANSWER-ALS Screening Visit | 0 | 1 | NA | 3 | 4 | 4 | ‚ãØ | 0 | 1 | 4 | 4 | 4 | 1 | NA | 43 | 2 | NA | . CASE-NEUAA599TMX | NEUAA599TMX | ALSFRS-R | ANSWER-ALS Screening Visit | 0 | 1 | NA | 2 | 4 | 2 | ‚ãØ | 0 | 1 | 2 | 4 | 4 | 1 | NA | 33 | 2 | NA | . CASE-NEUAB000NKC | NEUAB000NKC | ALSFRS-R | ANSWER-ALS Screening Visit | 0 | 1 | NA | 4 | 4 | 4 | ‚ãØ | 0 | 1 | 4 | 4 | 4 | 1 | NA | 40 | 2 | NA | . CASE-NEUAC617GR5 | NEUAC617GR5 | ALSFRS-R | ANSWER-ALS Screening Visit | 0 | 1 | NA | 3 | 4 | 3 | ‚ãØ | 0 | 1 | 3 | 4 | 4 | 1 | NA | 33 | 2 | NA | . CASE-NEUAD142RRY | NEUAD142RRY | ALSFRS-R | ANSWER-ALS Screening Visit | 0 | 1 | NA | 2 | 3 | 2 | ‚ãØ | 0 | 1 | 1 | 3 | 3 | 2 | NA | 28 | 2 | NA | . dbGetQuery(conn, glue_sql( &quot;SELECT `Participant_ID`, `Visit_Name`, `Visit_Date`, `alsfrst` FROM (SELECT `LHS`.`Participant_ID`, `Visit_Name`, `Visit_Date`, `alsfrst` FROM (SELECT `Participant_ID` FROM `aals_participants` WHERE ((`Sex` = &#39;Male&#39;) AND (`Cohort` = &#39;ALS&#39;)) LIMIT 5) AS `LHS` INNER JOIN `ALSFRS_R` AS `RHS` ON (`LHS`.`Participant_ID` = `RHS`.`Participant_ID`) ) ORDER BY `Participant_ID`, `Visit_Date`&quot; )) %&gt;% ggplot(aes(x = Visit_Date, y = alsfrst, color = Participant_ID)) + geom_point() + geom_line() . Disconnecting . When we don&#39;t need to access the datasebase any more, we disconnect. . dbDisconnect(conn) .",
            "url": "https://tomsing1.github.io/blog/answerals/r/colab/2021/01/30/Creating-SQLite-databases-using-R.html",
            "relUrl": "/answerals/r/colab/2021/01/30/Creating-SQLite-databases-using-R.html",
            "date": " ‚Ä¢ Jan 30, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Distinguishing stages of fruitfly development with a convolutional neural network",
            "content": "!pip install -Uqq fastbook import fastbook from fastbook import * . The fastai book starts with a toy example to demonstrate the power of deep learning for image classification: distinguishing images of teddy bears and actual bears. (A vignette that documents the fastai methods and functions used here is available here. . Here, I am using images of early and late stage fruitfly embryos [^1] and follow the fastai code to classify them into the two categories using a Convolutional neural network (CNN). . Note: The stages shown here do not correspond to the canonical stages of Drosophila embryogenesis, but to the six bins into which they were grouped by the BDGP curators. . The images are already available in the project&#39;s folder in my gDrive, in the thumbnails subdirectory. . from google.colab import drive # mount gDrive for persistent storage as outlined here: # https://colab.research.google.com/notebooks/io.ipynb#scrollTo=RWSJpsyKqHjH drive.mount(&#39;/content/drive&#39;, force_remount=True) # and create a subdirectory to store the files for this project !mkdir -p /content/drive/My Drive/colab_data/bdgp # then make it the working directory %cd /content/drive/My Drive/colab_data/bdgp . Mounted at /content/drive /content/drive/My Drive/colab_data/bdgp . path = &#39;thumbnails&#39; . First, I use fastai&#39;s built-in functions to identify and verify the available images. . fns = get_image_files(path) failed = verify_images(fns) print(f&#39;Removing {len(failed)} images that could not be opened.&#39;) failed.map(Path.unlink); . Removing 0 images that could not be opened. . Images from the two classes - early (stage 1) and late (stage 6) - are stored in separate subfolders within the thumbnails directory. The parent_label argument instructs the DataBlock function to use the directory names as labels. . embryos = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . Here are a few examples of the available images, together with their class labels. . dls = embryos.dataloaders(path) dls.valid.show_batch(max_n=8, nrows=2) . print(f&#39;The dataset contains {dls.n} images from {dls.n_subsets} classes.&#39;) . The dataset contains 344 images from 2 classes. . Next, I apply the same preprocessing steps used for the bear examples in the fastai book, e.g. resizing the images and applying the default set of transformations. . Note: The BDGP project already performed a lot of manual preprocessing, e.g. most of the images are centered on a single embryo, observed from the same perspective (a lateral view). That said, the dataset is not perfect, and a few images contain parts of neighboring embryos and / or the embryos are not perfectly aligned. . embryos = embryos.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = embryos.dataloaders(path) . Transfer learning with the restnet18 model for four epoch&#39;s generates a model with near perfect classification accuracy for this classification task. . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 0.968861 | 0.289360 | 0.081395 | 00:02 | . epoch train_loss valid_loss error_rate time . 0 | 0.402836 | 0.142101 | 0.069767 | 00:02 | . 1 | 0.310641 | 0.114935 | 0.058140 | 00:02 | . 2 | 0.240189 | 0.071903 | 0.023256 | 00:02 | . 3 | 0.192141 | 0.044318 | 0.023256 | 00:02 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . The misclassification error rate on the test set is very low - this is a promising start for my deep learning journey! . interp.print_classification_report() . precision recall f1-score support stage1 0.97 0.97 0.97 40 stage6 0.98 0.98 0.98 46 accuracy 0.98 86 macro avg 0.98 0.98 0.98 86 weighted avg 0.98 0.98 0.98 86 . Two misclassified images are shown below. One of them actually contains 1.5 embryos, one from each stage - and it is understandable that the model got confused. . interp.plot_top_losses(2, nrows=1) .",
            "url": "https://tomsing1.github.io/blog/bdgp/python/colab/fastai/2021/01/18/Early-vs-late-stage-classification.html",
            "relUrl": "/bdgp/python/colab/fastai/2021/01/18/Early-vs-late-stage-classification.html",
            "date": " ‚Ä¢ Jan 18, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Batch downloading thumbnail images from the BDGP FTP server",
            "content": "from functools import lru_cache import os import random import urllib import pandas as pd from pathlib import Path from google.colab import drive from PIL import Image . # mount gDrive for persistent storage as outlined here: # https://colab.research.google.com/notebooks/io.ipynb#scrollTo=RWSJpsyKqHjH drive.mount(&#39;/content/drive&#39;, force_remount=True) # and create a subdirectory to store the files for this project !mkdir -p /content/drive/My Drive/colab_data/bdgp # then make it the working directory %cd /content/drive/My Drive/colab_data/bdgp . Mounted at /content/drive /content/drive/My Drive/colab_data/bdgp . Batch downloading images . To download a specific subset of in situ hybridization images from the BDGP FTP server, I first download the image metadata file (in CSV format) and store it in this project&#39;s directory on gDrive. . To avoid re-downloading the same images, I set the download_images variable here: . download_images = False . @lru_cache(maxsize=None) def retrieve_image_metadata(path=None): &quot;Load BDGP metadata from a local (cached) or remote CSV file&quot; server = &quot;https://insitu.fruitfly.org/&quot; if path and os.path.isfile(path): print(f&quot;Reading image metadata from cached file {path}.&quot;) images = pd.read_csv(path) else: image_metadata = server + &quot;insitu-mysql-dump/insitu_images.csv.gz&quot; print(f&quot;Downloading image metadata from {image_metadata}.&quot;) images = pd.read_csv(image_metadata, header=None, compression=&quot;gzip&quot;, encoding=&quot;latin1&quot;, index_col=False, names=[&#39;id&#39;,&#39;symbol&#39;, &#39;annotation_symbol&#39;, &#39;FBgn&#39;, &#39;cDNA_clone&#39;, &#39;path&#39;, &#39;stage&#39;, &#39;pov&#39;, &#39;comment&#39;, &#39;resolution&#39;]) if path: print(f&quot;Caching metadata as {path}.&quot;) images.to_csv(path) images[&quot;stage&quot;] = images[&quot;stage&quot;].astype(&#39;category&#39;) images = images[images.path.notna()] return images def retrieve_images(paths, outdir, ftp_root=&#39;ftp://ftp.fruitfly.org/pub/&#39; &#39;insitu_image_storage/thumbnails/&#39;): &quot;Copy an impages from the BDGP FTP server to the output directory&quot; outdir = Path(outdir) os.makedirs(outdir, exist_ok=True) for path in paths: try: response = urllib.request.urlopen(ftp_root + path).read() path = Path(path).name with open(outdir / path, &#39;wb&#39;) as handler: handler.write(response) except urllib.error.HTTPError as e: print(f&#39;{path.name}: HTTPError: {e.code}&#39;) next() except: print(path) next() . With the two functions to 1) load the metadata DataFrame and 2) copy images from the BDGP&#39;s FTP server to my gDrive folder in place, I am ready to retrieve a small subset of the available dataset: I random select 200 lateral thumbnails from both 1) early and 2) late stage embryos. These images can serve as a first step for my image analysis journey and I copy them to my project&#39;s gDrive folder. . metadata = retrieve_image_metadata(&#39;insitu_images.csv.gz&#39;) stage1 = metadata .query(&#39;stage == 1 and resolution == &quot;low&quot; and pov == &quot;lateral&quot;&#39;) .sample(200, random_state=123) .path .tolist() stage6 = metadata .query(&#39;stage == 6 and resolution == &quot;low&quot; and pov == &quot;lateral&quot;&#39;) .sample(200, random_state=123) .path .tolist() . Reading image metadata from cached file insitu_images.csv.gz. . if download_images: retrieve_images(stage1, outdir=&quot;thumbnails/stage1&quot;) retrieve_images(stage6, outdir=&quot;thumbnails/stage6&quot;) . Let&#39;s take a quick peek at a random image from each class, e.g. one early-stage and one late-stage embryo: . random.seed(123) Image.open(Path(&quot;thumbnails/stage1&quot;) / Path(random.choice(stage1)).name) . random.seed(123) Image.open(Path(&quot;thumbnails/stage6&quot;) / Path(random.choice(stage6)).name) .",
            "url": "https://tomsing1.github.io/blog/bdgp/python/colab/gdrive/2021/01/18/Batch-downloading-BDGP-images.html",
            "relUrl": "/bdgp/python/colab/gdrive/2021/01/18/Batch-downloading-BDGP-images.html",
            "date": " ‚Ä¢ Jan 18, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Exploring metadata & images from the BDGBP gene expression project",
            "content": "from functools import lru_cache from PIL import Image from pathlib import Path from io import BytesIO import urllib.request import pandas as pd import numpy as np import matplotlib.pyplot as plt . Image metadata . The BDGP project has shared metadata about the collected images in the following CSV files: . server = &quot;https://insitu.fruitfly.org/&quot; image_metadata = server + &quot;insitu-mysql-dump/insitu_images.csv.gz&quot; image_annotations = server + &quot;insitu-mysql-dump/insitu_annot.csv.gz&quot; . def retrieve_image(path): &quot;Retrieve an impage from the BDGP FTP server&quot; root = &#39;ftp://ftp.fruitfly.org/pub/insitu_image_storage/thumbnails/&#39; response = urllib.request.urlopen(root + path).read() return Image.open(BytesIO(response)) def display_multiple_img(x, rows=1, cols=1, figsize=None, title=None): &quot;&quot;&quot;Plot a list of images&quot;&quot;&quot; figure, ax = plt.subplots(nrows=rows,ncols=cols,figsize=figsize, constrained_layout=True) for ind,img in enumerate(x): ax.ravel()[ind].imshow(img) ax.ravel()[ind].set_axis_off() if title: figure.suptitle(title) plt.show() . After some trial and error, I figured out that the CSV files are latin1 encoded (e.g. not UTF-8). The provided files do not contain column names, so I added them myself. . @lru_cache(maxsize=None) def retrieve_image_metadata(): images = pd.read_csv(image_metadata, header=None, compression=&quot;gzip&quot;, encoding=&quot;latin1&quot;, index_col=False, names=[&#39;id&#39;,&#39;symbol&#39;, &#39;annotation_symbol&#39;, &#39;FBgn&#39;, &#39;cDNA_clone&#39;, &#39;path&#39;, &#39;stage&#39;, &#39;pov&#39;, &#39;comment&#39;, &#39;resolution&#39;]) images[&quot;stage&quot;] = images[&quot;stage&quot;].astype(&#39;category&#39;) return images @lru_cache(maxsize=None) def retrieve_annotations(): annotations = pd.read_csv(image_annotations, header=None, compression=&quot;gzip&quot;, encoding=&quot;latin1&quot;, index_col=False, names=[&#39;id&#39;, &#39;annoation_symbol&#39;, &#39;FBgn&#39;, &#39;stage&#39;, &#39;description&#39;]) return annotations . images = retrieve_image_metadata() annotations = retrieve_annotations() . The images DataFrame contains information about each image: . id: The identifier of the targeted gene | symbol and annotation_symbol: The gene symbol of the targeted gene | FBgn: The Flybase identifier of the target gene | cDNA_clone | path: The path to the image file, relative to the root of the FTP server (see below) | stage: The developmental stage (binned into 6 categories, see below) | pov: The point of view of the image (e.g. the orientation of the embryo) | comment | resolution | . images.sample(5, random_state=123).style . id symbol annotation_symbol FBgn cDNA_clone path stage pov comment resolution . 14685 CG1139 | CG1139 | CG1139 | FBgn0035300 | LP06969-dg | production_images/insituLP06969-dg_1.jpe | 1 | nan | nan | nan | . 114051 CG7263 | AIF | AIF | FBgn0031392 | FI05215 | img_dir_179/insitu179269.jpe | 6 | lateral | nan | nan | . 1318 CG10072 | sgl | sgl | FBgn0010851 | SD09476 | img_dir_10/insitu10741.jpe | 6 | lateral | AP_inverted | low | . 10732 CG11048 | CG11048 | CG11048 | FBgn0034487 | GH24459 | img_dir_17/insitu17662.jpe | 2 | lateral | nan | low | . 73804 CG3297 | mnd | mnd | FBgn0002778 | LD25378-dg | img_dir_63/insitu63344.jpe | 3 | lateral | nan | low | . The annotations DataFrame provides additional information for each gene, e.g. the . id | annotation_symbol | FBgn | stage | description | . columns. The former can be used for joining the image-level information, while the description contains the curator&#39;s description of the observed gene expression patterns. . annotations.sample(5, random_state=123).style . id annoation_symbol FBgn stage description . 29365 CG17158 | cpb | FBgn0011570 | 5 | procrystal cell | . 30863 CG17530 | GstE6 | FBgn0063494 | 6 | embryonic dorsal epidermis | . 73387 CG6854 | CG6854 | FBgn0036478 | 6 | embryonic/larval muscle system | . 70738 CG6417 | Oatp33Eb | FBgn0032435 | 6 | embryonic proventriculus inner layer | . 26431 CG1572 | CG1572 | FBgn0030309 | 6 | ventral midline | . For each gene, the annotations DataFrame can contain multiple rows, each with a different description term and / or for a different developmental stage. For example, here are the first annotation rows for the cpb gene: . annotations.query(f&#39;id == &quot;CG17158&quot;&#39;) .head() .style . id annoation_symbol FBgn stage description . 29355 CG17158 | cpb | FBgn0011570 | 1 | maternal | . 29356 CG17158 | cpb | FBgn0011570 | 2 | ubiquitous | . 29357 CG17158 | cpb | FBgn0011570 | 3 | faint ubiquitous | . 29358 CG17158 | cpb | FBgn0011570 | 4 | amnioserosa | . 29359 CG17158 | cpb | FBgn0011570 | 4 | head mesoderm primordium P2 | . The BDGP project has collected tens of thousands of images, across the 16 stages of embryogenesis. The stages column indicates all 16 developmental stages of Drosophila melanogaster development, binned as follows: . Stages Bin . Stage 1-3 | 1 | . Stage 4-6 | 2 | . Stage 7-8 | 3 | . Stage 9-10 | 4 | . Stage 11-12 | 5 | . Stage 13-16 | 6 | . The following code chunks explore some summary statistics of this dataset, e.g. the number of unique gene symbols (8295), the number of cDNA clones (10002) and the different positions and resolutions the images were taken at. . images.describe() . id symbol annotation_symbol FBgn cDNA_clone path stage pov comment resolution . count 138867 | 136765 | 136765 | 133368 | 138867 | 138865 | 138867 | 123866 | 4661 | 80589 | . unique 8393 | 8295 | 8314 | 8221 | 10002 | 133451 | 6 | 3 | 3 | 2 | . top CG9930 | E5 | E5 | FBgn0008646 | CG17390-cm | img_dir_13/insitu13306.jpe | 6 | lateral | AP_inverted | low | . freq 458 | 458 | 458 | 458 | 169 | 3 | 43125 | 73959 | 2480 | 71577 | . Developmental stages . The largest number of images are from late stage embryos: . images.stage.value_counts(dropna=False) . 6 43125 5 28663 2 20502 1 16985 4 15561 3 14031 Name: stage, dtype: int64 . To get a first idea of what types of images are available, I next pulled five random examples from each of the six stage bins and displayed them. (Images come in two sizes, full-size and thumbnails, in two separate directories. Here I will retrieve the thumbnails only.) . Images . The full collection of images is available for download via FTP at ftp://ftp.fruitfly.org/pub/insitu_image_storage. . Images are available in three different sizes: . Multiple embryos per image: . Production images show a whole field of embryos, including different developmental stages, orientations, etc. | . Single embryos per images: . Thumbnails show each embryo in 263 x 113 pixels. | Smallest images were scaled to 420 x 180 pixels. | Small images show a single embryo with 945 x 405 pixels. | Large images are 2100 x 900 pixels in size. | . For each size, the images are available in subdirectories (e.g. img_dir_0, img_dir_1, etc. . URLs . The URL for each image can be constructed by concatenating the FTP server&#39;s URL with the relative path provided in the image metadata file. . Missing images . A small subset of rows in the metadata file is missing the path entry, e.g. there is not associated image available. These rows must be filtered (or downstream steps must be able to deal with missing values.) . images[images.path.isna()] . id symbol annotation_symbol FBgn cDNA_clone path stage pov comment resolution . 4395 CG10383 | CG10383 | CG10383 | FBgn0032699 | LD21810 | NaN | 6 | NaN | NaN | low | . 121627 CG8153 | mus210 | mus210 | FBgn0004698 | LD47533-dg | NaN | 1 | lateral | NaN | low | . The remaining rows have valid path entries and point to image files, e.g. here are randome exampkes from each of the annotated (binned) developmental stages: . n_images = 5 thumbnails = {} for stage in range(1,7): selected_images = images.query(f&#39;stage == {stage}&#39;) .path.sample(n_images, random_state=1234) .tolist() thumbnails[f&#39;stage {stage}&#39;] = [ retrieve_image(x) for x in selected_images] . for stage in thumbnails.keys(): display_multiple_img(thumbnails[stage], rows=1, cols=5, figsize=(10,2), title=stage) . A few potential challenges are illustrated: . Some images contain more than one embryo, sometimes many more. | Images were taken at different magnification settins, e.g. some were zoomed in to display more detail and cropped. | The orientation of the embryos is not the same, e.g. some images are flipped or rotated. | Most images show lateral views, but some images were taken from a dorsal or ventral perspective. | . images.path.str.match(&#39;production&#39;).value_counts(dropna=False) . False 133342 True 5523 NaN 2 Name: path, dtype: int64 . Almost all of these production_images lack annotations about their resolution: . images[images.path.str.match(&#39;production&#39;, na=False)] .resolution.value_counts(dropna=False) . NaN 5521 low 2 Name: resolution, dtype: int64 . selected_images = images[images.path.str.match(&#39;production&#39;, na=False)] .path.sample(15, random_state=1234) .tolist() thumbnails = [retrieve_image(x) for x in selected_images] . display_multiple_img(thumbnails, rows=3, cols=5, figsize=(10,6), title=&quot;production_images&quot;) . Image resolution . Most images . images.resolution.value_counts(dropna=False) . low 71577 NaN 58278 high 9012 Name: resolution, dtype: int64 . thumbnails = {} for resolution in images.resolution.dropna().unique().tolist(): selected_images = images.query(f&#39;resolution == &quot;{resolution}&quot;&#39;) .path.sample(n_images, random_state=123) .tolist() thumbnails[resolution] = [ retrieve_image(x) for x in selected_images] . The high-resolution images are quite variable, e.g. they cofus on different parts of an embryo. . for category in thumbnails.keys(): display_multiple_img(thumbnails[category], rows=1, cols=5, figsize=(10,2), title=category) . Image orientation . Images are annotated with the orientation of the embryo. Most of them are lateral views. (There are two lateral views, so it&#39;s more likely that embryos will come to rest in that position.) A sizable fraction of images has not been annotated with this information (NaN) . images.pov.value_counts(dropna=False) . lateral 73959 dorsal 37126 NaN 15001 ventral 12781 Name: pov, dtype: int64 . Here are a few examples for each of the three orientations. . thumbnails = {} for pov in images.pov.dropna().unique().tolist(): selected_images = images.query(f&#39;pov == &quot;{pov}&quot;&#39;) .path.sample(n_images, random_state=123) .tolist() thumbnails[pov] = [ retrieve_image(x) for x in selected_images] for category in thumbnails.keys(): display_multiple_img(thumbnails[category], rows=1, cols=5, figsize=(10,2), title=category) . Inverted orientations . The comment column indicates that a subset of images is inverted with respect to the standard orientation. . images.comment.value_counts() . AP_inverted 2480 DV_inverted 1142 AP_DV_inverted 1039 Name: comment, dtype: int64 . thumbnails = {} for comment in images.comment.dropna().unique().tolist(): selected_images = images.query(f&#39;comment == &quot;{comment}&quot;&#39;) .path.sample(n_images, random_state=123) .tolist() thumbnails[comment] = [ retrieve_image(x) for x in selected_images] for category in thumbnails.keys(): display_multiple_img(thumbnails[category], rows=1, cols=5, figsize=(10,2), title=category) . paths = images.sample(10, random_state=123).path.tolist() thumbnails = [retrieve_image(x) for x in paths] . plt.figure(figsize=(15,4)) for num, x in enumerate(thumbnails): plt.subplot(1,len(thumbnails),num+1) plt.axis(&#39;off&#39;) plt.imshow(x) .",
            "url": "https://tomsing1.github.io/blog/bdgp/python/2020/12/11/Retrieving-BDGP-images.html",
            "relUrl": "/bdgp/python/2020/12/11/Retrieving-BDGP-images.html",
            "date": " ‚Ä¢ Dec 11, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastai: Drosophila embryogenesis",
            "content": "To learn more about deep learning methods, I have begun working through the fastai book. . As always, the best way for me to learn is to dive into a small project of my own - an attitude strongly supported by the fastai authors. . The book uses image classification as an example, so I decided to look for a suitable image analysis project to help me learn. . Years ago, I studied the development of the fruitfly , especially the formation of its muscle system during embryogenesis. . . So I decided to return to my scientific roots and explore images of fruitfly embryogenesis. . The BDGP project . In 2009 the Berkeley Drosophila Genome Project documented the expression patterns of most fruitfly genes using in situ hybridization. The researcherstook a large number of digital images of individual embryos, each stained with a specific probe to highlight the transcripts of one gene. . In total, the BDGP project examined 8532 genes and documented them with 140427 digital photographs. . Embryonic development takes about 22 hours and has been subdivided into separate stages discernable under the microscope. . . Here is the expression of one gene, Ecdysone-inducible gene L2 (* ImpL2*) at stage 7 of development, for example: . . Gene expression is dynamic, e.g. it changes over time as the embryo develops. To see how ImpL2 changes over time, check out the BDGP‚Äôs full report . After staining and imaging a large number of fruitfly embryos (Weiszmann et al, 2009), the researchers carefully . Identified single embryos in the field of view, and cropped the image accordingly. | Oriented each image so that the anterior end of the embryo faced left. | Assigned a developmental stage. | Described the (often complex) expression patterns they observed using a controlled vocabulary of anatomical terms. | Using this large image dataset, the BDGP project performed and published numerous analyses, e.g. . Global analysis of patterns of gene expression during Drosophila embryogenesis | . . Systematic image-driven analysis of the spatial Drosophila embryonic expression landscape | A quantitative spatiotemporal atlas of gene expression in the Drosophila blastoderm | . and many more. . The images have been made available publicly, e.g. via this site - 250 GB of image data in total. . Other researchers have used this resource and implemented machine learning models, e.g. . Automated annotation of developmental stages of Drosophila embryos | AnnoFly: annotating Drosophila embryonic images based on an attention-enhanced RNN model | Deep Low-Shot Learning for Biological Image Classification | . Unfortunately, the FTP server requires a login/password, which is not provided on the page. The [contacts](https://insitu.fruitfly.org/cgi-bin/ex/insitu.pl?t=html&amp;p=contact_us) form seems to be broken (not surprising for a website of a research project conducted more than 10 years ago). I contaced [Susan Celniker](https://www.genetics.org/content/204/3/845), a researcher at the Lawrence Berkeley National Laborator and key driver of the Drosophila genome / BDGP efforts to see if she could help me out ü§ûüèª. The BDGP FTP server is up serving anonmous requests without a login again! Thanks a lot, BDGP team! . Fly-FISH . Another project used fluorescent microscopy to generate even higher resolution images of gene expression patterns during fruitfly embryogenesis: Fly-FISH . The images have sub-cellular resolution and are beautiful: .",
            "url": "https://tomsing1.github.io/blog/fastai/fruitflies/2020/11/29/BDGP_in_situ_hybridization.html",
            "relUrl": "/fastai/fruitflies/2020/11/29/BDGP_in_situ_hybridization.html",
            "date": " ‚Ä¢ Nov 29, 2020"
        }
        
    
  
    
  
    
        ,"post6": {
            "title": "Diving into python (again)",
            "content": "When I first started to use computational methods as a PhD student, python was the first programming language I learned. I loved both it‚Äôs clear syntax and the philosophy behind it. More recently, I have mainly been using R for my analyses, but still return to python e.g. to write multi-step workflows e.g. using Snakemake or Luigi. . In 2018, I had a chance to attend the fastai course taught by Jeremy Howard at the University of San Francisco. It was a great introduction into the field, but unfortunately I didn‚Äôt find the time to dive more deeply into it. Luckily, the fastai team just published much of their material as a book and also made the underlying Jupyter notebooks available. Time for another deep dive into neural networks, python, Jupyter notebooks, Numpy an more! . First, I needed to remind myself of a few features of python, e.g. the different types of methods used in object oriented programming or how to use the relatively recent pathlib standard module. . Here are a few online resources I found helpful: . Python . Virtual environments | Instance, class and static methods | Paths in python &gt;= 3.4 and this handy cheat sheet | Python string formatting | . Working in Jupyter . Jupyter debugger | . Numpy . Indexing arrays | Axes | . Matplotlib . Tutorial A Figure object is the outermost container for a matplotlib graphic, which can contain multiple Axes objects. One source of confusion is the name: an Axes actually translates into what we think of as an individual plot or graph. . | . Graphviz . Examples | .",
            "url": "https://tomsing1.github.io/blog/python/fastai/2020/11/07/python.html",
            "relUrl": "/python/fastai/2020/11/07/python.html",
            "date": " ‚Ä¢ Nov 7, 2020"
        }
        
    
  
    
  
    
  
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Personal blog of Thomas Sandmann, a Computational Biologist working at Denali Therapeutics in South San Francisco, California, USA 1. . I am passionate and opinionated about many things, including neuroscience, oncology, drug discovery, genetics, teaching, and learning new things. Oh, and cats üêà. . If you are curious about my work, check out my Google Scholar profile. . The opinions expressed here are solely my own and do not express the views or opinions of my employer .¬†&#8617; . |",
          "url": "https://tomsing1.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://tomsing1.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}